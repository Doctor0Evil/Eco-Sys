# FAQ and Risks: Neuro‑EcoKarma v1.0
`docs/public/faq_and_risks_v1.0.md`

## Q1. Does this system read my mind?

**No.** The architecture is designed specifically to *avoid* any use of brain data, neural telemetry, or inferred mental states. All computations are based on environmental measurements and standardized life‑cycle data about products and activities.

Your inner thoughts, beliefs, and feelings are out of scope, by design.

## Q2. What data does it use, then?

The system uses:

- Environmental data: pollutant concentrations, litter indices, etc.
- Activity logs you voluntarily provide (e.g., trips, consumption, disposal).
- Public life‑cycle databases (e.g., product footprints).

It does **not** use medical records, brain scans, or personality profiles.

## Q3. What is my “Karma score”?

Your Karma score is a running tally of the estimated environmental impact of your actions over time, adjusted for:

- How harmful each pollutant is.
- How vulnerable the local context is.

It is:

- A tool for conditioning certain high‑impact permissions.
- Not a measure of your moral worth or legal status.

## Q4. Can my Karma be used to deny basic rights?

No.

The architecture is built with the principle that:

- **Basic rights**—like freedom of thought, bodily integrity, basic movement, and due process—do **not** depend on ecological Karma.
- **Conditional privileges**—like operating certain devices or obtaining specific licenses—can be tied to Karma and ecological safety.

Any attempt to extend Karma to basic rights would violate the neurorights and human‑rights assumptions underlying this protocol.

## Q5. Could this become a “Karma caste system”?

It could, if designed poorly. To avoid that:

- All λ‑weights and thresholds must be public and contestable.
- Restorative pathways must be realistic and accessible.
- Distributional analyses must be run to detect and correct unfair patterns (e.g., if low‑income people are disproportionately restricted).

The goal is to nudge and support responsibility, not to create permanent underclasses.

## Q6. What about privacy?

We minimize data and protect it:

- Only environmental and activity data needed for impact calculation are stored.
- Identifiers can be pseudonymized for research.
- Logs and ledgers can be implemented with strong encryption and access controls.
- Data protection laws (e.g., GDPR‑style) still apply.

## Q7. Who controls the weights and thresholds?

Ideally:

- Thresholds and λ‑weights are proposed by experts (health, environment, ethics).
- They are then debated and adopted (or rejected) through participatory processes—citizen assemblies, public consultations, etc.
- They are periodically reviewed in light of new evidence and public feedback.

No single company or agency should unilaterally set them.

## Q8. Can I opt out?

In a pilot:

- Participation should be voluntary; you can opt out at any time, within legal requirements.
- You can always see your own data and request correction of errors.

In broader deployments, rules will depend on local law. Even where some environmental accounting is mandatory, the use of personal‑level Karma scoring should remain consent‑based or carefully justified.

## Q9. What if the data are wrong?

The system includes:

- Error detection (e.g., outlier checks, sensor diagnostics).
- An appeals process where you can challenge specific entries or decisions.
- Audit trails so independent reviewers can trace how a score was computed.

Incorrect data and unfair decisions should be reversible.

## Q10. How does this help the planet, really?

By:

- Making environmental impact visible at the level of individual and institutional behavior.
- Tying certain powerful actions (like high‑impact deployments) to demonstrated responsibility.
- Embedding restorative justice, so past harm can be actively compensated.

It is not a silver bullet, but it is a framework for making ecological responsibility systematic, transparent, and aligned with respect for the mind.
